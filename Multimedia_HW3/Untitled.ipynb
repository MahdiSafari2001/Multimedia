{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02cb3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = './Shapes.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "#blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edges = cv2.Canny(blurred, 50, 200)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Function to detect shape name\n",
    "def detect_shape(c):\n",
    "    shape = \"unidentified\"\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    # Adjust the epsilon value to improve accuracy\n",
    "    epsilon = 0.02 * peri  # Experiment with this value\n",
    "    approx = cv2.approxPolyDP(c, epsilon, True)\n",
    "    \n",
    "    if len(approx) == 3:\n",
    "        shape = \"triangle\"\n",
    "    elif len(approx) == 4:\n",
    "        (x, y, w, h) = cv2.boundingRect(approx)\n",
    "        ar = w / float(h)\n",
    "        shape = \"square\" if ar >= 0.95 and ar <= 1.05 else \"rectangle\"\n",
    "    elif len(approx) == 5:\n",
    "        shape = \"pentagon\"\n",
    "    elif len(approx) == 6:\n",
    "        shape = \"hexagon\"\n",
    "    else:\n",
    "        shape = \"circle\"\n",
    "    \n",
    "    return shape\n",
    "\n",
    "\n",
    "# Create copies for both tasks\n",
    "labeled_image = image.copy()\n",
    "quadrilateral_image = image.copy()\n",
    "\n",
    "# Detect shapes and label them\n",
    "for contour in contours:\n",
    "    shape_name = detect_shape(contour)\n",
    "    \n",
    "    M = cv2.moments(contour)\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    cv2.drawContours(labeled_image, [contour], -1, (0, 255, 0), 2)\n",
    "                                                    # contour colors\n",
    "    cv2.putText(labeled_image, shape_name, (cX - 20, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                                                                                            # text color\n",
    "# Remove non-quadrilateral shapes\n",
    "for contour in contours:\n",
    "    shape_name = detect_shape(contour)\n",
    "    if shape_name not in [\"square\", \"rectangle\"]:\n",
    "        cv2.drawContours(quadrilateral_image, [contour], -1, (0, 0, 0), -1)\n",
    "\n",
    "# Save and display the images\n",
    "cv2.imwrite('./labeled_shapes.jpg', labeled_image)\n",
    "cv2.imwrite('./quadrilateral_shapes.jpg', quadrilateral_image)\n",
    "\n",
    "cv2.imshow(\"Labeled Shapes\", labeled_image)\n",
    "cv2.imshow(\"Quadrilateral Shapes\", quadrilateral_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52293cd5",
   "metadata": {},
   "source": [
    "<p dir = \"rtl\">\n",
    "    ابتدا شکل اصلی را خوانده و نمایش می دهیم. سپس در ادامه تصور را سیاه و سفید می کنیم و با اعمال یک فیلتر گاسین و ادج دیتکشن کنی میایم و کانتور های عکس را پیدا می کنیم.\n",
    "    </p>\n",
    "    <p dir = \"rtl\">\n",
    "    یک تابع detect_shape داریم که با استفاده از تعداد خمیدگی تعداد ضلع ها را می شمارد و بر اساس تعداد ضلع نام های آن ها را در خروجی تابع قرار می دهد.\n",
    "    در ادامه نیز نوشته های سفید رنگ که اسم های شکل هاست بر روی آنها اضافه می کند و عکس را نمایش می دهد\n",
    "</p>\n",
    "<p dir = \"rtl\">\n",
    "    در آخر هم با توجه به اینکه شکل ها را تشخیص داده شکل های چهارضلعی مربع و مستطیل را نگه می دارد و داخل باقی شکل ها را سیاه می کند به منظور اینکه آن شکل ها را حذف کرده است.\n",
    "    </p>\n",
    "    \n",
    "<p dir = \"rtl\">\n",
    "    نکته مهم و تست شده در این کد این است که کد دارای باگی است که ما قادر به رفع آن نشدیم و این مشکل تشخیص یکی از مثلث ها به عنوان شش ضلعی است که با تست هایی که انجام دادیم دیدیم اگر فیلتر گاسین 3 در 3 اعمال کنیم یکی از مثلث ها حذف می شود و دیگری هم با فیلتر گاسین 5 در 5 مثلث دیگر حذف می شود.\n",
    "    می توان از اشتراک این دو حالت چهارضلعی ها را به صورت ایده آل داشت اما تضمینی نیست که در عکس دیگری همین عملکرد را داشته باشد به همین خاطر راه ثابت و منطقی ای نیست.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0ace3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farms 1\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = './FARMS.png'\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Compute area of each contour\n",
    "areas = [(cv2.contourArea(c), c) for c in contours]\n",
    "areas.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Create a copy of the image to draw on\n",
    "labeled_image = image.copy()\n",
    "\n",
    "# Assign ranks based on area\n",
    "for rank, (area, contour) in enumerate(areas, 1):\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] == 0:\n",
    "        continue\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    cv2.drawContours(labeled_image, [contour], -1, (0, 255, 0), 2)\n",
    "    cv2.putText(labeled_image, str(rank), (cX - 10, cY + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Save and display the labeled image\n",
    "cv2.imwrite('./labeled_farms.jpg', labeled_image)\n",
    "cv2.imshow(\"Labeled Farms\", labeled_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd070fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farms 2\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = './FARMS_2.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Compute area of each contour\n",
    "areas = [(cv2.contourArea(c), c) for c in contours]\n",
    "areas.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Create a copy of the image to draw on\n",
    "labeled_image = image.copy()\n",
    "\n",
    "# Assign ranks based on area\n",
    "for rank, (area, contour) in enumerate(areas, 1):\n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] == 0:\n",
    "        continue\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    cv2.drawContours(labeled_image, [contour], -1, (0, 255, 0), 2)\n",
    "    cv2.putText(labeled_image, str(rank), (cX - 10, cY + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Save and display the labeled image\n",
    "cv2.imwrite('./labeled_farms.jpg', labeled_image)\n",
    "cv2.imshow(\"Labeled Farms\", labeled_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7602f7f",
   "metadata": {},
   "source": [
    "<p dir = \"rtl\">\n",
    "    ابتدا شکل اصلی را خوانده. سپس در ادامه تصور را سیاه و سفید می کنیم و با اعمال یک فیلتر گاسین و ادج دیتکشن کنی میایم و کانتور های عکس را پیدا می کنیم.\n",
    "    </p>\n",
    "    <p dir = \"rtl\">\n",
    "    سپس مساحت هر ناحیه از کانتور ها را پیدا کرده و بر اساس لاندا به صورت reverse یعنی از ناحیه بزرگ به ناحیه کوچک عدد گذاری می کند و با فونت آبی آن ها را داخلش می نویسد.  \n",
    "</p>\n",
    "\n",
    "<p dir = \"rtl\">\n",
    "    نکته مهم و تست شده در این کد این است که کد دارای باگی است که ما قادر به رفع آن نشدیم و این مشکل تشخیص زمین ها است که کم و زیاد مشخص می کند و علت این زیاد مشخص کردن مرز های کلفت زمین ها است و از طرفی هم اگر فیلتر اعمالی را در کرنل های بزرگتر اعمال کنیم دقت لبه یابی پایین می آید و همین باعث شمارش کم و یا زیاد زمین ها می شود.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1638896b",
   "metadata": {},
   "source": [
    "<p dir=\"rtl\">\n",
    "    کتابخانه مورد نیاز برای دستور زیر را در anaconda prompt یا ترمینال لینوکس وارد کنید:\n",
    "    </p>\n",
    "    <p>\n",
    "    pip install opencv-python-headless torch torchvision pillow tkinter\n",
    "    </p>\n",
    "    <p>\n",
    "    conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "    </p>\n",
    "    <p>\n",
    "    https://gist.github.com/ageitgey/4e1342c10a71981d0b491e1b8227328b\n",
    "    </p>\n",
    "    <p>\n",
    "    برای نصب پای تورچ، پیلو برای خواندن عکس و تینکر برای محیط gui این بخش\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0a3139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained ResNet model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Define image transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read the class labels\n",
    "class_labels = {}\n",
    "with open('imagenet_classes.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        index, label = line.strip().split(', ')\n",
    "        class_labels[int(index)] = label\n",
    "\n",
    "def select_image():\n",
    "    # Function to select an image file and display it\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        image = Image.open(file_path)\n",
    "        image = ImageTk.PhotoImage(image)\n",
    "        panel.configure(image=image)\n",
    "        panel.image = image\n",
    "        root.filename = file_path\n",
    "\n",
    "def capture_image():\n",
    "    # Function to capture an image from the webcam and display it\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imwrite('capture.jpg', frame)\n",
    "    image = Image.open('capture.jpg')\n",
    "    image = ImageTk.PhotoImage(image)\n",
    "    panel.configure(image=image)\n",
    "    panel.image = image\n",
    "    root.filename = 'capture.jpg'\n",
    "\n",
    "def classify_image():\n",
    "    # Function to classify the displayed image\n",
    "    image_path = root.filename\n",
    "    image = Image.open(image_path)\n",
    "    image = preprocess(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    # Map the predicted index to the corresponding class name\n",
    "    predicted_class = class_labels[predicted.item()]\n",
    "    result.config(text=f'Predicted class: {predicted_class}')\n",
    "\n",
    "# Set up the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Classifier\")\n",
    "\n",
    "# Add GUI elements\n",
    "panel = tk.Label(root)\n",
    "panel.pack()\n",
    "select_button = tk.Button(root, text='Select Image', command=select_image)\n",
    "select_button.pack()\n",
    "capture_button = tk.Button(root, text='Capture Image', command=capture_image)\n",
    "capture_button.pack()\n",
    "classify_button = tk.Button(root, text='Classify Image', command=classify_image)\n",
    "classify_button.pack()\n",
    "result = tk.Label(root, text='Classified class will appear here')\n",
    "result.pack()\n",
    "\n",
    "# Start the GUI\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68007e9",
   "metadata": {},
   "source": [
    "<p dir = \"rtl\">\n",
    "    با استفاده از تینکر و پای تورچ و شبکه رس نت یک اپلیکیشن با زبان پایتون نوشته ایم که بر اساس فایل imagenet_classes.txt که از گیت هاب پیدا کردیم و اعداد در کنار آن نوشته است.\n",
    "    تشخیص این برنامه و خروجی اصلی این تابع یک عدد است که با خواندن آن فایل مرتب شده بر اساس اعداد به جواب نام آن میرسیم و در خروجی نمایش می دهیم.\n",
    "    عکس می تواند از روی کامپیوتر یا با استفاده از وب کم لپ تاپ به برنامه داده شود و برنامه با دکمه classify image بعد از اینکه عکس را از وب کم یا از کامپیوتر برداشت و به ما نشان داد نوع آن را تشخیص دهد.\n",
    "    </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
